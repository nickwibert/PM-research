data <- subset(Smarket, select = -Today)
# randomly split data into training and test data sets
n <- nrow(data)
i <- sample(seq_len(n))
x_train <- data[i[1:(n/2)],]
x_test <- data[i[(n/2 + 1):n],]
head(x_train)
# randomly split data into training and test data sets
n <- nrow(Smarket)
i <- sample(seq_len(n))
train <- Smarket[i[1:(n/2)],]
test <- Smarket[i[(n/2 + 1):n],]
# separate outcome and covariates
x_train <- subset(train, select = -Today)
x_train
head(train)
head(x_train)
y_train <- subset(train, select = Today)
head(y_train)
test
x_test <- subset(test, select = -Today)
x_test
# randomly split data into training and test data sets
n <- nrow(Smarket)
i <- sample(seq_len(n))
train <- Smarket[i[1:(n/2)],]
test <- Smarket[i[(n/2 + 1):n],]
# separate outcome and covariates
x_train <- subset(train, select = -Today)
y_train <- subset(train, select = Today)
x_test <- subset(test, select = -Today)
## use KNN loop from problem 2 to determine the optimal choice of k
# vector of error rates (index will correspond to choice of k)
error_rates <- numeric(400)
# perform KNN for values of k from 1 to 400 and store test error rate on each iteration
for (k in 1:400)
{
y_hat <- knn(x_train, x_test, y_train, k)
fail <- (data$y[501:1000] != y_hat)
error_rates[k] <- mean(fail)
}
x_train <- cbind(X1 = data$x1[1:500], X2 = data$x2[1:500])
y_train <- data$y[1:500]
x_test <- cbind(X1 = data$x1[501:1000], X2 = data$x2[501:1000])
y_test <- data$y[501:1000]
y_hat <- knn(train = x_train, test = x_test, cl = y_train, k = 3)
x_train <- cbind(X1 = data$x1[1:500], X2 = data$x2[1:500])
y_train <- data$y[1:500]
x_test <- cbind(X1 = data$x1[501:1000], X2 = data$x2[501:1000])
y_test <- data$y[501:1000]
y_hat <- knn(train = x_train, test = x_test, cl = y_train, k = 3)
load("Data/Problem2.dat")
# setting random seed for reproducibility
set.seed(12345)
# vector of known probabilities of Y|X given by the normal CDF
prob <- pnorm(0.5*data$x1 - 0.4*data$x2)
# vector of predicted values
y_hat <- ifelse(prob > 0.5, 1, 0)
# vector of failures (1 when y != y_hat, and 0 when y = y_hat)
fail <- (data$y != y_hat)
mean(fail[1:500]) # training error
mean(fail[501:1000]) # test error
x_train <- cbind(X1 = data$x1[1:500], X2 = data$x2[1:500])
y_train <- data$y[1:500]
x_test <- cbind(X1 = data$x1[501:1000], X2 = data$x2[501:1000])
y_test <- data$y[501:1000]
y_hat <- knn(train = x_train, test = x_test, cl = y_train, k = 3)
# vector of failures (note that y_hat has only 500 values this time)
fail <- (y_test != y_hat)
mean(fail) # test error
x_train <- cbind(X1 = data$x1[1:500], X2 = data$x2[1:500])
y_train <- data$y[1:500]
x_test <- cbind(X1 = data$x1[501:1000], X2 = data$x2[501:1000])
y_test <- data$y[501:1000]
y_hat <- knn(train = x_train, test = x_test, cl = y_train, k = 3)
# vector of failures (note that y_hat has only 500 values this time)
fail <- (y_test != y_hat)
mean(fail) # test error
x_train <- cbind(X1 = data$x1[1:500], X2 = data$x2[1:500])
y_train <- data$y[1:500]
x_test <- cbind(X1 = data$x1[501:1000], X2 = data$x2[501:1000])
y_test <- data$y[501:1000]
y_hat <- knn(train = x_train, test = x_test, cl = y_train, k = 3)
# vector of failures (note that y_hat has only 500 values this time)
fail <- (y_test != y_hat)
mean(fail) # test error
x_train <- cbind(X1 = data$x1[1:500], X2 = data$x2[1:500])
y_train <- data$y[1:500]
x_test <- cbind(X1 = data$x1[501:1000], X2 = data$x2[501:1000])
y_test <- data$y[501:1000]
y_hat <- knn(train = x_train, test = x_test, cl = y_train, k = 3)
# vector of failures (note that y_hat has only 500 values this time)
fail <- (y_test != y_hat)
mean(fail) # test error
x_train <- cbind(X1 = data$x1[1:500], X2 = data$x2[1:500])
y_train <- data$y[1:500]
x_test <- cbind(X1 = data$x1[501:1000], X2 = data$x2[501:1000])
y_test <- data$y[501:1000]
y_hat <- knn(train = x_train, test = x_test, cl = y_train, k = 3)
# vector of failures (note that y_hat has only 500 values this time)
fail <- (y_test != y_hat)
mean(fail) # test error
x_train <- cbind(X1 = data$x1[1:500], X2 = data$x2[1:500])
y_train <- data$y[1:500]
x_test <- cbind(X1 = data$x1[501:1000], X2 = data$x2[501:1000])
y_test <- data$y[501:1000]
y_hat <- knn(train = x_train, test = x_test, cl = y_train, k = 3)
# vector of failures (note that y_hat has only 500 values this time)
fail <- (y_test != y_hat)
mean(fail) # test error
x_train <- cbind(X1 = data$x1[1:500], X2 = data$x2[1:500])
y_train <- data$y[1:500]
x_test <- cbind(X1 = data$x1[501:1000], X2 = data$x2[501:1000])
y_test <- data$y[501:1000]
y_hat <- knn(train = x_train, test = x_test, cl = y_train, k = 3)
# vector of failures (note that y_hat has only 500 values this time)
fail <- (y_test != y_hat)
mean(fail) # test error
# combine existing training/test data with xrandom for a total of 22 covariates
x_train <- cbind(data$x1[1:500], data$x2[1:500], data$xrandom[1:500,])
x_test <- cbind(data$x1[501:1000], data$x2[501:1000], data$xrandom[501:1000,])
y_hat <- knn(x_train, x_test, y_train, 40)
fail <- (y_test != y_hat)
mean(fail) # test error
# combine existing training/test data with xrandom for a total of 22 covariates
x_train <- cbind(data$x1[1:500], data$x2[1:500], data$xrandom[1:500,])
x_test <- cbind(data$x1[501:1000], data$x2[501:1000], data$xrandom[501:1000,])
y_hat <- knn(x_train, x_test, y_train, 40)
fail <- (y_test != y_hat)
mean(fail) # test error
y_test <- subset(test, select = Today)
head(test)
head(y_test)
# randomly split data into training and test data sets
n <- nrow(Smarket)
i <- sample(seq_len(n))
train <- Smarket[i[1:(n/2)],]
test <- Smarket[i[(n/2 + 1):n],]
# separate outcome and covariates
x_train <- subset(train, select = -Today)
y_train <- subset(train, select = Today)
x_test <- subset(test, select = -Today)
y_test <- subset(test, select = Today)
## use KNN loop from problem 2 to determine the optimal choice of k
# vector of error rates (index will correspond to choice of k)
error_rates <- numeric(400)
# perform KNN for values of k from 1 to 400 and store test error rate on each iteration
for (k in 1:400)
{
y_hat <- knn(x_train, x_test, y_train, k)
fail <- (y_test != y_hat)
error_rates[k] <- mean(fail)
}
dim(x_train)
dim(x_test)
dim(y_train)
dim(y_test)
length(x_train)
length(y_train)
train[,8]
length(train[,8])
length(train[,-8])
length(x_train)
length(y_train)
x_train)
x_train
y_train
seq_len(n)
t(y_train)
# randomly split data into training and test data sets
n <- nrow(Smarket)
i <- sample(seq_len(n))
train <- Smarket[i[1:(n/2)],]
test <- Smarket[i[(n/2 + 1):n],]
# separate outcome and covariates
x_train <- subset(train, select = -Today)
y_train <- subset(train, select = Today)
x_test <- subset(test, select = -Today)
y_test <- subset(test, select = Today)
## use KNN loop from problem 2 to determine the optimal choice of k
# vector of error rates (index will correspond to choice of k)
error_rates <- numeric(400)
# perform KNN for values of k from 1 to 400 and store test error rate on each iteration
for (k in 1:400)
{
y_hat <- knn(x_train, x_test, t(y_train), k)
fail <- (y_test != y_hat)
error_rates[k] <- mean(fail)
}
t(y_train)
y_train[,1]
# randomly split data into training and test data sets
n <- nrow(Smarket)
i <- sample(seq_len(n))
train <- Smarket[i[1:(n/2)],]
test <- Smarket[i[(n/2 + 1):n],]
# separate outcome and covariates
x_train <- subset(train, select = -Today)
y_train <- subset(train, select = Today)
x_test <- subset(test, select = -Today)
y_test <- subset(test, select = Today)
## use KNN loop from problem 2 to determine the optimal choice of k
# vector of error rates (index will correspond to choice of k)
error_rates <- numeric(400)
# perform KNN for values of k from 1 to 400 and store test error rate on each iteration
for (k in 1:400)
{
y_hat <- knn(x_train, x_test, y_train[,1], k)
fail <- (y_test != y_hat)
error_rates[k] <- mean(fail)
}
# randomly split data into training and test data sets
n <- nrow(Smarket)
i <- sample(seq_len(n))
train <- Smarket[i[1:(n/2)],]
test <- Smarket[i[(n/2 + 1):n],]
# separate outcome and covariates
x_train <- subset(train, select = -Today)
y_train <- subset(train, select = Today)
x_test <- subset(test, select = -Today)
y_test <- subset(test, select = Today)
## use KNN loop from problem 2 to determine the optimal choice of k
# vector of error rates (index will correspond to choice of k)
error_rates <- numeric(400)
# perform KNN for values of k from 1 to 400 and store test error rate on each iteration
for (k in 1:400)
{
y_hat <- knn(x_train, x_test, y_train, k)
fail <- (y_test != y_hat)
error_rates[k] <- mean(fail)
}
# randomly split data into training and test data sets
n <- nrow(Smarket)
i <- sample(seq_len(n))
train <- Smarket[i[1:(n/2)],]
test <- Smarket[i[(n/2 + 1):n],]
# separate outcome and covariates
x_train <- subset(train, select = -Today)
y_train <- subset(train, select = Today)
x_test <- subset(test, select = -Today)
y_test <- subset(test, select = Today)
## use KNN loop from problem 2 to determine the optimal choice of k
# vector of error rates (index will correspond to choice of k)
error_rates <- numeric(400)
# perform KNN for values of k from 1 to 400 and store test error rate on each iteration
for (k in 1:400)
{
y_hat <- knn(x_train, x_test, y_train[,1], k)
fail <- (y_test != y_hat)
error_rates[k] <- mean(fail)
}
# randomly split data into training and test data sets
n <- nrow(Smarket)
i <- sample(seq_len(n))
train <- Smarket[i[1:(n/2)],]
test <- Smarket[i[(n/2 + 1):n],]
# separate outcome and covariates
x_train <- as.data.frame(subset(train, select = -Today))
y_train <- as.data.frame(subset(train, select = Today))
x_test <- as.data.frame(subset(test, select = -Today))
y_test <- as.data.frame(subset(test, select = Today))
## use KNN loop from problem 2 to determine the optimal choice of k
# vector of error rates (index will correspond to choice of k)
error_rates <- numeric(400)
# perform KNN for values of k from 1 to 400 and store test error rate on each iteration
for (k in 1:400)
{
y_hat <- knn(x_train, x_test, y_train, k)
fail <- (y_test != y_hat)
error_rates[k] <- mean(fail)
}
# randomly split data into training and test data sets
n <- nrow(Smarket)
i <- sample(seq_len(n))
train <- Smarket[i[1:(n/2)],]
test <- Smarket[i[(n/2 + 1):n],]
# separate outcome and covariates
x_train <- subset(train, select = -Today)
y_train <- subset(train, select = Today)
x_test <- subset(test, select = -Today)
y_test <- subset(test, select = Today)
## use KNN loop from problem 2 to determine the optimal choice of k
# vector of error rates (index will correspond to choice of k)
error_rates <- numeric(400)
# perform KNN for values of k from 1 to 400 and store test error rate on each iteration
for (k in 1:400)
{
y_hat <- knn(x_train, x_test, y_train[,1], k)
fail <- (y_test != y_hat)
error_rates[k] <- mean(fail)
}
# randomly split data into training and test data sets
n <- nrow(Smarket)
i <- sample(seq_len(n))
train <- Smarket[i[1:(n/2)],]
test <- Smarket[i[(n/2 + 1):n],]
# separate outcome and covariates
x_train <- subset(train, select = -Today)
y_train <- subset(train, select = Today)
x_test <- subset(test, select = -Today)
y_test <- subset(test, select = Today)
## use KNN loop from problem 2 to determine the optimal choice of k
# vector of error rates (index will correspond to choice of k)
error_rates <- numeric(400)
# perform KNN for values of k from 1 to 400 and store test error rate on each iteration
for (k in 1:400)
{
y_hat <- knn(x_train[drop=FALSE], x_test[drop=FALSE], y_train, k)
fail <- (y_test != y_hat)
error_rates[k] <- mean(fail)
}
as.matrix(y_train)
# randomly split data into training and test data sets
n <- nrow(Smarket)
i <- sample(seq_len(n))
train <- Smarket[i[1:(n/2)],]
test <- Smarket[i[(n/2 + 1):n],]
# separate outcome and covariates
x_train <- subset(train, select = -Today)
y_train <- subset(train, select = Today)
x_test <- subset(test, select = -Today)
y_test <- subset(test, select = Today)
## use KNN loop from problem 2 to determine the optimal choice of k
# vector of error rates (index will correspond to choice of k)
error_rates <- numeric(400)
# perform KNN for values of k from 1 to 400 and store test error rate on each iteration
for (k in 1:400)
{
y_hat <- knn(x_train, x_test, as.matrix(y_train), k)
fail <- (y_test != y_hat)
error_rates[k] <- mean(fail)
}
# randomly split data into training and test data sets
n <- nrow(Smarket)
i <- sample(seq_len(n))
train <- Smarket[i[1:(n/2)],]
test <- Smarket[i[(n/2 + 1):n],]
# separate outcome and covariates
x_train <- subset(train, select = -Today)
y_train <- as.matrix(subset(train, select = Today))
x_test <- subset(test, select = -Today)
y_test <- subset(test, select = Today)
## use KNN loop from problem 2 to determine the optimal choice of k
# vector of error rates (index will correspond to choice of k)
error_rates <- numeric(400)
# perform KNN for values of k from 1 to 400 and store test error rate on each iteration
for (k in 1:400)
{
y_hat <- knn(x_train, x_test, y_train, k)
fail <- (y_test != y_hat)
error_rates[k] <- mean(fail)
}
head(Smarket)
head(Smarket, select=-Today)
head(Smarket, select=-Today)
head(Smarket[-Today])
head(Smarket[select=-Today])
head(Smarket[-Today])
train <- Smarket[i, -8]
head(train)
train[,-8]
head(train[,-8])
head(train)
# remove Today from data
data <- subset(Smarket, select = -Today)
# remove Today from data
data <- subset(Smarket, select = -Today)
# randomly split data into training and test data sets
n <- nrow(data)
i <- sample(seq_len(n))
train <- data[i[1:(n/2)],]
test <- data[i[(n/2 + 1):n],]
# separate outcome and covariates
x_train <- subset(train, select = -Direction)
y_train <- subset(train, select = Direction)
x_test <- subset(test, select = -Direction)
y_test <- subset(test, select = Direction)
## use KNN loop from problem 2 to determine the optimal choice of k
# vector of error rates (index will correspond to choice of k)
error_rates <- numeric(400)
# perform KNN for values of k from 1 to 400 and store test error rate on each iteration
for (k in 1:400)
{
y_hat <- knn(x_train, x_test, y_train, k)
fail <- (y_test != y_hat)
error_rates[k] <- mean(fail)
}
head(test)
head(x_test)
# remove Today from data
data <- subset(Smarket, select = -Today)
# randomly split data into training and test data sets
n <- nrow(data)
i <- sample(seq_len(n))
train <- data[i[1:(n/2)],]
test <- data[i[(n/2 + 1):n],]
# separate outcome and covariates
x_train <- train[,-8]
y_train <- train[,8]
x_test <- test[,-8]
y_test <- test[,8]
## use KNN loop from problem 2 to determine the optimal choice of k
# vector of error rates (index will correspond to choice of k)
error_rates <- numeric(400)
# perform KNN for values of k from 1 to 400 and store test error rate on each iteration
for (k in 1:400)
{
y_hat <- knn(x_train, x_test, y_train, k)
fail <- (y_test != y_hat)
error_rates[k] <- mean(fail)
}
plot(error_rates, xlab = 'k', ylab = 'Test Error Rate')
min(error_rates)       # minimum test error rate
which.min(error_rates) # corresponding choice of k
class(x_train)
class(y_train)
class(y_test)
class(x_test)
x_train <- subset(data, select=-Direction)
class(x_train)
# remove Today from data
data <- subset(Smarket, select = -Today)
# randomly split data into training and test data sets
n <- nrow(data)
i <- sample(seq_len(n))
train <- data[i[1:(n/2)],]
test <- data[i[(n/2 + 1):n],]
# separate outcome and covariates
x_train <- train[,-8]
y_train <- train[,8]
x_test <- test[,-8]
y_test <- test[,8]
## use KNN loop from problem 2 to determine the optimal choice of k
# vector of error rates (index will correspond to choice of k)
error_rates <- numeric(400)
# perform KNN for values of k from 1 to 400 and store test error rate on each iteration
for (k in 1:400)
{
y_hat <- knn(x_train, x_test, y_train, k)
fail <- (y_test != y_hat)
error_rates[k] <- mean(fail)
}
y_train <- subset(data, select=Direction)
class(y_train)
as.factor(y_train)
y <- as.factor(y_train)
y
x_test <- test[,-Direction]
# remove Today from data
data <- subset(Smarket, select = -Today)
# randomly split data into training and test data sets
n <- nrow(data)
i <- sample(seq_len(n))
train <- data[i[1:(n/2)],]
test <- data[i[(n/2 + 1):n],]
# separate outcome and covariates (Direction is column number 8)
x_train <- train[,-8]
y_train <- train[,8]
x_test <- test[,-8]
y_test <- test[,8]
## use KNN loop from problem 2 to determine the optimal choice of k
# vector of error rates (index will correspond to choice of k)
error_rates <- numeric(400)
# perform KNN for values of k from 1 to 400 and store test error rate on each iteration
for (k in 1:400)
{
y_hat <- knn(x_train, x_test, y_train, k)
fail <- (y_test != y_hat)
error_rates[k] <- mean(fail)
}
plot(error_rates, xlab = 'k', ylab = 'Test Error Rate')
min(error_rates)       # minimum test error rate
which.min(error_rates) # corresponding choice of k
sqrt(3)
sqrt(2)
sqrt(2 + sqrt(2))
sqrt(2 + sqrt(2 + sqrt(2)))
sqrt(2 + sqrt(2 + sqrt(2 + sqrt(2))))
sqrt(2)
sqrt(2*sqrt(2))
sqrt(2*sqrt(2*sqrt(2)))
sqrt(2*sqrt(2*sqrt(2*sqrt(2))))
1-(1/9999999999)
1-(1/99999)
library(ncdf4)
library(raster)
library(cluster)
data_dir <- "C:/Users/nickw/OneDrive/Desktop/UF/Undergrad Research/PM-research/data/Annual"
setwd(data_dir)
names <- c("BC", "NH4", "NIT", "OM", "SO4", "SOIL", "SS")
files <- c()
# get annual data for all components in the year 2000
for (name in names)
{
files <- append(files,
file.path(name,
list.files(path = file.path(data_dir, name),
pattern="200012.nc")))
}
r <- stack(files)
e <- as(extent(-124.848974, -66.885444, 24.396308, 49.384358), 'SpatialPolygons')
crs(e) <- "+proj=longlat +datum=WGS84 +no_defs"
usa <- crop(r, e)
# take only 1% of the data
usa.sample <- sampleRandom(usa, size=(dim(usa)[1]*dim(usa)[2]*0.01), xy=TRUE, na.rm=TRUE)
# perform k-means clustering, store cluster id in data frame
usa.sample <- data.frame(usa.sample, k = kmeans(usa.sample, 10)$cluster)
# plot data points where color is determined by cluster
plot(usa.sample$x, usa.sample$y, col = usa.sample$k+1,
xlab = "Latitude", ylab = "Longitude",
main = "K-Means Clustering for 2000 (using all components)",
cex.main=0.8, cex.lab = 0.7, cex.axis = 0.6)
